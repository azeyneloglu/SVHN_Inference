{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0083e9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from numpy import random\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras import layers\n",
    "#from keras.layers import Input, Dense, Activation, Flatten\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.regularizers import l1\n",
    "np.random.seed(5)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "786588ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.initializers import glorot_uniform\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc292123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17505293056418702392\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7880757343399939470\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3046847284\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 14771074576768593826\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12543404174442539188\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "585a72d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device found : [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "physical_device = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(f'Device found : {physical_device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c317f085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data\n",
    "train = scipy.io.loadmat('train_32x32.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e3bb298",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train['X']\n",
    "train_y = train['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "aa2962ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra = scipy.io.loadmat('extra_32x32.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "947275e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_x = extra['X']\n",
    "extra_y = extra['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a85d2632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3, 531131)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "166b508f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(531131, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "735faaa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(273257, 32, 32, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "405c7aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_x = extra_x[:,:,:,:200000]\n",
    "extra_y = extra_y[:200000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "491ae86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra = None\n",
    "del extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a501545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.moveaxis(train_x, -1, 0)\n",
    "\n",
    "extra_x = np.moveaxis(extra_x, -1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a2a9168",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.vstack((train_x, extra_x))\n",
    "train_y = np.vstack((train_y, extra_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7867e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.astype('float64')\n",
    "train_x /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25e81605",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = int(len(train_x) / 4)\n",
    "\n",
    "train_x_1 = train_x[:temp]\n",
    "train_x_2 = train_x [temp: 2*temp]\n",
    "train_x_3 = train_x [2*temp: 3*temp]\n",
    "train_x_4 = train_x [3*temp: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69042ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropandUpsampleImage (X):\n",
    "    \n",
    "    X = tf.image.crop_to_bounding_box(\n",
    "    X, 1, 6, 25, 22)\n",
    "    \n",
    "    X = tf.image.resize(\n",
    "    X, [32,32], method='bilinear', preserve_aspect_ratio=False,\n",
    "    antialias=False)\n",
    "    \n",
    "    return X\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2d67598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since this is a memory intensive process, process images in chunks\n",
    "temp = int(len(train_x) / 20)\n",
    "for i in range (0, len(train_x), int(len(train_x) / 20) ):\n",
    "    \n",
    "    train_x[i:i+temp] = cropandUpsampleImage(train_x[i:i+temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b455ee4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "train_labels = train_y.astype('int64')\n",
    "lb = LabelBinarizer()\n",
    "train_labels = lb.fit_transform(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f186636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(273257, 32, 32, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9cb11f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(273257, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1ae274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "084ffd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_x, train_labels,\n",
    "                                                  test_size=0.15, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6189cc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the test set\n",
    "test = scipy.io.loadmat('test_32x32.mat')\n",
    "test_x = test['X']\n",
    "test_y = test['y']\n",
    "\n",
    "test_x = test_x.astype('float64')\n",
    "test_x /= 255.0\n",
    "\n",
    "test_x = np.moveaxis(test_x, -1, 0)\n",
    "\n",
    "test_x = tf.image.crop_to_bounding_box(\n",
    "    test_x , 1, 6, 25, 22\n",
    ")\n",
    "test_x  = tf.image.resize(\n",
    "   test_x , [32,32], method='bilinear', preserve_aspect_ratio=False,\n",
    "    antialias=False\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "test_labels = test_y.astype('int64')\n",
    "lb = LabelBinarizer()\n",
    "test_labels = lb.fit_transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f71dbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convBlock (X, filters, kernel_size, initializer = glorot_uniform, training = True):\n",
    "    \n",
    "    X = Conv2D (filters=filters, kernel_size = kernel_size, strides = 1, padding = \"same\", kernel_initializer = initializer(seed=10))(X)\n",
    "    X = BatchNormalization(axis=3)(X, training = False)\n",
    "    X = Activation ('relu') (X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e271403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createCustomModel(input_shape=(32,32,3), num_classes = 10):\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = convBlock(X_input,32,(3,3))\n",
    "    \n",
    "    X = convBlock(X,64,(3,3))\n",
    "    \n",
    "    X = convBlock(X,128,(3,3))\n",
    "    \n",
    "    \n",
    "    X = Flatten(name='flatten')(X)\n",
    "    X = Dense(256, activation='relu', name='fc1')(X)\n",
    "    X = Dropout(0.2,seed=10)(X)\n",
    "    X = Dense(128, activation='relu', name='fc2')(X)\n",
    "    X = Dropout(0.3,seed=10)(X)\n",
    "    X = Dense(64, activation='relu', name='fc3')(X)\n",
    "    X = Dropout(0.2,seed=10)(X)\n",
    "    X = Dense(num_classes, activation='softmax', name='predictions')(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bc7ebc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "  2/686 [..............................] - ETA: 19s - loss: 3.1375 - accuracy: 0.1406WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0169s vs `on_train_batch_end` time: 0.0388s). Check your callbacks.\n",
      "686/686 [==============================] - 42s 61ms/step - loss: 1.6398 - accuracy: 0.4289 - val_loss: 0.5828 - val_accuracy: 0.8226\n",
      "Epoch 2/60\n",
      "686/686 [==============================] - 41s 60ms/step - loss: 0.7264 - accuracy: 0.7771 - val_loss: 0.4180 - val_accuracy: 0.8738\n",
      "Epoch 3/60\n",
      "686/686 [==============================] - 41s 60ms/step - loss: 0.5730 - accuracy: 0.8271 - val_loss: 0.3522 - val_accuracy: 0.8953\n",
      "Epoch 4/60\n",
      "686/686 [==============================] - 41s 60ms/step - loss: 0.5154 - accuracy: 0.8447 - val_loss: 0.3304 - val_accuracy: 0.9012\n",
      "Epoch 5/60\n",
      "686/686 [==============================] - 41s 60ms/step - loss: 0.4768 - accuracy: 0.8574 - val_loss: 0.3188 - val_accuracy: 0.9040\n",
      "Epoch 6/60\n",
      "686/686 [==============================] - 41s 60ms/step - loss: 0.4480 - accuracy: 0.8672 - val_loss: 0.3065 - val_accuracy: 0.9095\n",
      "Epoch 7/60\n",
      "686/686 [==============================] - 42s 61ms/step - loss: 0.4301 - accuracy: 0.8732 - val_loss: 0.3196 - val_accuracy: 0.9085\n",
      "Epoch 8/60\n",
      "686/686 [==============================] - 42s 61ms/step - loss: 0.4165 - accuracy: 0.8763 - val_loss: 0.2878 - val_accuracy: 0.9163\n",
      "Epoch 9/60\n",
      "686/686 [==============================] - 42s 61ms/step - loss: 0.3941 - accuracy: 0.8835 - val_loss: 0.2846 - val_accuracy: 0.9147\n",
      "Epoch 10/60\n",
      "686/686 [==============================] - 42s 62ms/step - loss: 0.3838 - accuracy: 0.8866 - val_loss: 0.2831 - val_accuracy: 0.9165\n",
      "Epoch 11/60\n",
      "686/686 [==============================] - 43s 62ms/step - loss: 0.3709 - accuracy: 0.8902 - val_loss: 0.2740 - val_accuracy: 0.9198\n",
      "Epoch 12/60\n",
      "686/686 [==============================] - 43s 62ms/step - loss: 0.3654 - accuracy: 0.8927 - val_loss: 0.2753 - val_accuracy: 0.9187\n",
      "Epoch 13/60\n",
      "686/686 [==============================] - 43s 62ms/step - loss: 0.3548 - accuracy: 0.8950 - val_loss: 0.2788 - val_accuracy: 0.9191\n",
      "Epoch 14/60\n",
      "686/686 [==============================] - 43s 63ms/step - loss: 0.3523 - accuracy: 0.8956 - val_loss: 0.2762 - val_accuracy: 0.9199\n",
      "Epoch 15/60\n",
      "686/686 [==============================] - 43s 63ms/step - loss: 0.3420 - accuracy: 0.8988 - val_loss: 0.2741 - val_accuracy: 0.9226\n",
      "Epoch 16/60\n",
      "686/686 [==============================] - 43s 63ms/step - loss: 0.3351 - accuracy: 0.9023 - val_loss: 0.2675 - val_accuracy: 0.9221\n",
      "Epoch 17/60\n",
      "686/686 [==============================] - 43s 63ms/step - loss: 0.3282 - accuracy: 0.9031 - val_loss: 0.2582 - val_accuracy: 0.9242\n",
      "Epoch 18/60\n",
      "686/686 [==============================] - 43s 63ms/step - loss: 0.3233 - accuracy: 0.9047 - val_loss: 0.2678 - val_accuracy: 0.9236\n",
      "Epoch 19/60\n",
      "686/686 [==============================] - 43s 63ms/step - loss: 0.3199 - accuracy: 0.9060 - val_loss: 0.2661 - val_accuracy: 0.9243\n",
      "Epoch 20/60\n",
      "686/686 [==============================] - 43s 63ms/step - loss: 0.3185 - accuracy: 0.9063 - val_loss: 0.2717 - val_accuracy: 0.9226\n",
      "Epoch 21/60\n",
      "686/686 [==============================] - 43s 63ms/step - loss: 0.3134 - accuracy: 0.9076 - val_loss: 0.2663 - val_accuracy: 0.9245\n",
      "Epoch 22/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.3078 - accuracy: 0.9100 - val_loss: 0.2683 - val_accuracy: 0.9228\n",
      "Epoch 23/60\n",
      "686/686 [==============================] - 43s 63ms/step - loss: 0.2681 - accuracy: 0.9215 - val_loss: 0.2416 - val_accuracy: 0.9319\n",
      "Epoch 24/60\n",
      "686/686 [==============================] - 43s 63ms/step - loss: 0.2602 - accuracy: 0.9238 - val_loss: 0.2380 - val_accuracy: 0.9320\n",
      "Epoch 25/60\n",
      "686/686 [==============================] - 44s 63ms/step - loss: 0.2571 - accuracy: 0.9250 - val_loss: 0.2487 - val_accuracy: 0.9292\n",
      "Epoch 26/60\n",
      "686/686 [==============================] - 43s 63ms/step - loss: 0.2548 - accuracy: 0.9245 - val_loss: 0.2384 - val_accuracy: 0.9325\n",
      "Epoch 27/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2474 - accuracy: 0.9272 - val_loss: 0.2369 - val_accuracy: 0.9322\n",
      "Epoch 28/60\n",
      "686/686 [==============================] - 43s 63ms/step - loss: 0.2428 - accuracy: 0.9286 - val_loss: 0.2375 - val_accuracy: 0.9330\n",
      "Epoch 29/60\n",
      "686/686 [==============================] - 43s 63ms/step - loss: 0.2428 - accuracy: 0.9283 - val_loss: 0.2385 - val_accuracy: 0.9326\n",
      "Epoch 30/60\n",
      "686/686 [==============================] - 43s 63ms/step - loss: 0.2415 - accuracy: 0.9296 - val_loss: 0.2395 - val_accuracy: 0.9327\n",
      "Epoch 31/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2377 - accuracy: 0.9298 - val_loss: 0.2417 - val_accuracy: 0.9313\n",
      "Epoch 32/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2360 - accuracy: 0.9307 - val_loss: 0.2382 - val_accuracy: 0.9327\n",
      "Epoch 33/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2280 - accuracy: 0.9327 - val_loss: 0.2357 - val_accuracy: 0.9330\n",
      "Epoch 34/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2272 - accuracy: 0.9333 - val_loss: 0.2344 - val_accuracy: 0.9339\n",
      "Epoch 35/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2257 - accuracy: 0.9344 - val_loss: 0.2338 - val_accuracy: 0.9339\n",
      "Epoch 36/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2276 - accuracy: 0.9342 - val_loss: 0.2345 - val_accuracy: 0.9344\n",
      "Epoch 37/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2221 - accuracy: 0.9357 - val_loss: 0.2346 - val_accuracy: 0.9335\n",
      "Epoch 38/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2268 - accuracy: 0.9348 - val_loss: 0.2352 - val_accuracy: 0.9335\n",
      "Epoch 39/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2221 - accuracy: 0.9344 - val_loss: 0.2337 - val_accuracy: 0.9347\n",
      "Epoch 40/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2248 - accuracy: 0.9341 - val_loss: 0.2343 - val_accuracy: 0.9338\n",
      "Epoch 41/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2203 - accuracy: 0.9356 - val_loss: 0.2347 - val_accuracy: 0.9338\n",
      "Epoch 42/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2175 - accuracy: 0.9366 - val_loss: 0.2344 - val_accuracy: 0.9341\n",
      "Epoch 43/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2218 - accuracy: 0.9351 - val_loss: 0.2343 - val_accuracy: 0.9336\n",
      "Epoch 44/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2190 - accuracy: 0.9363 - val_loss: 0.2339 - val_accuracy: 0.9334\n",
      "Epoch 45/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2208 - accuracy: 0.9358 - val_loss: 0.2336 - val_accuracy: 0.9338\n",
      "Epoch 46/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2190 - accuracy: 0.9362 - val_loss: 0.2338 - val_accuracy: 0.9339\n",
      "Epoch 47/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2222 - accuracy: 0.9349 - val_loss: 0.2338 - val_accuracy: 0.9343\n",
      "Epoch 48/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2147 - accuracy: 0.9368 - val_loss: 0.2340 - val_accuracy: 0.9338\n",
      "Epoch 49/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2206 - accuracy: 0.9364 - val_loss: 0.2341 - val_accuracy: 0.9343\n",
      "Epoch 50/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2192 - accuracy: 0.9354 - val_loss: 0.2340 - val_accuracy: 0.9341\n",
      "Epoch 51/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2189 - accuracy: 0.9360 - val_loss: 0.2341 - val_accuracy: 0.9343\n",
      "Epoch 52/60\n",
      "686/686 [==============================] - 45s 65ms/step - loss: 0.2209 - accuracy: 0.9362 - val_loss: 0.2334 - val_accuracy: 0.93407s - loss: 0 - E\n",
      "Epoch 53/60\n",
      "686/686 [==============================] - 44s 65ms/step - loss: 0.2191 - accuracy: 0.9355 - val_loss: 0.2335 - val_accuracy: 0.9336\n",
      "Epoch 54/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2195 - accuracy: 0.9367 - val_loss: 0.2333 - val_accuracy: 0.9338\n",
      "Epoch 55/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2206 - accuracy: 0.9355 - val_loss: 0.2335 - val_accuracy: 0.9343\n",
      "Epoch 56/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2177 - accuracy: 0.9369 - val_loss: 0.2334 - val_accuracy: 0.9343\n",
      "Epoch 57/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2175 - accuracy: 0.9368 - val_loss: 0.2337 - val_accuracy: 0.9345\n",
      "Epoch 58/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2208 - accuracy: 0.9361 - val_loss: 0.2334 - val_accuracy: 0.9339\n",
      "Epoch 59/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2177 - accuracy: 0.9369 - val_loss: 0.2335 - val_accuracy: 0.9339\n",
      "Epoch 60/60\n",
      "686/686 [==============================] - 44s 64ms/step - loss: 0.2202 - accuracy: 0.9362 - val_loss: 0.2340 - val_accuracy: 0.9340\n"
     ]
    }
   ],
   "source": [
    "my_model = createCustomModel(input_shape=(32,32,3), num_classes = 10)\n",
    "my_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.00001)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "\n",
    "history_my_model = my_model.fit(datagen.flow(X_train, y_train, batch_size=128),\n",
    "                              epochs=60, validation_data=(X_val, y_val),\n",
    "                               callbacks=[early_stopping,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53aaf57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def importVGG (num_trainable_layers):\n",
    "\n",
    "    model_vgg16_conv = VGG16(weights='imagenet', include_top=False, input_shape=(32,32,3))\n",
    "\n",
    "    if num_trainable_layers == 0:\n",
    "        for layer in model_vgg16_conv.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    for layer in model_vgg16_conv.layers[:(-1*num_trainable_layers)]:\n",
    "        layer.trainable=False\n",
    "        \n",
    "    return model_vgg16_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b598d44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVGG16Model(train_images, trainable_layers):\n",
    "\n",
    "    base_model = importVGG(trainable_layers)\n",
    "    img_shape = train_images.shape[1:]\n",
    "    num_classes = 10\n",
    "    #Create your own input formats\n",
    "    keras_input = Input(shape=img_shape, name = 'image_input')\n",
    "\n",
    "    #Use the generated model \n",
    "    output_vgg16_conv = base_model(keras_input)\n",
    "\n",
    "    # Add the fully-connected layers \n",
    "    My_vgg16 = Flatten(name='flatten')(output_vgg16_conv)\n",
    "    My_vgg16 = Dense(512, activation='relu', name='fc1')(My_vgg16)\n",
    "    My_vgg16 = Dropout(0.2,seed=10)(My_vgg16)\n",
    "    My_vgg16 = Dense(256, activation='relu', name='fc2')(My_vgg16)\n",
    "    My_vgg16 = Dropout(0.3,seed=10)(My_vgg16)\n",
    "    My_vgg16 = Dense(64, activation='relu', name='fc3')(My_vgg16)\n",
    "    My_vgg16 = Dropout(0.2,seed=10)(My_vgg16)\n",
    "    My_vgg16 = Dense(num_classes, activation='softmax', name='predictions')(My_vgg16)\n",
    "\n",
    "    #Create your own model \n",
    "    model = Model(inputs=keras_input, outputs=My_vgg16)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b39c9473",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=8,\n",
    "                             zoom_range=[0.95, 1.05],\n",
    "                             height_shift_range=0.10,\n",
    "                             shear_range=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b59d45e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  2/686 [..............................] - ETA: 20s - loss: 2.4139 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0239s vs `on_train_batch_end` time: 0.0362s). Check your callbacks.\n",
      "686/686 [==============================] - 46s 66ms/step - loss: 1.3060 - accuracy: 0.5456 - val_loss: 0.5416 - val_accuracy: 0.8425\n",
      "Epoch 2/50\n",
      "686/686 [==============================] - 46s 67ms/step - loss: 0.4977 - accuracy: 0.8687 - val_loss: 0.3697 - val_accuracy: 0.8988\n",
      "Epoch 3/50\n",
      "686/686 [==============================] - 46s 68ms/step - loss: 0.4002 - accuracy: 0.8940 - val_loss: 0.2977 - val_accuracy: 0.9198\n",
      "Epoch 4/50\n",
      "686/686 [==============================] - 48s 69ms/step - loss: 0.3506 - accuracy: 0.9068 - val_loss: 0.2691 - val_accuracy: 0.9259\n",
      "Epoch 5/50\n",
      "686/686 [==============================] - 48s 70ms/step - loss: 0.3210 - accuracy: 0.9158 - val_loss: 0.2749 - val_accuracy: 0.9287\n",
      "Epoch 6/50\n",
      "686/686 [==============================] - 48s 70ms/step - loss: 0.3034 - accuracy: 0.9203 - val_loss: 0.2931 - val_accuracy: 0.9181\n",
      "Epoch 7/50\n",
      "686/686 [==============================] - 48s 70ms/step - loss: 0.2859 - accuracy: 0.9253 - val_loss: 0.2596 - val_accuracy: 0.9330\n",
      "Epoch 8/50\n",
      "686/686 [==============================] - 48s 69ms/step - loss: 0.2698 - accuracy: 0.9288 - val_loss: 0.2459 - val_accuracy: 0.9360\n",
      "Epoch 9/50\n",
      "686/686 [==============================] - 48s 70ms/step - loss: 0.2616 - accuracy: 0.9308 - val_loss: 0.2475 - val_accuracy: 0.9345\n",
      "Epoch 10/50\n",
      "686/686 [==============================] - 48s 70ms/step - loss: 0.2487 - accuracy: 0.9350 - val_loss: 0.2303 - val_accuracy: 0.9373\n",
      "Epoch 11/50\n",
      "686/686 [==============================] - 48s 70ms/step - loss: 0.2378 - accuracy: 0.9374 - val_loss: 0.2291 - val_accuracy: 0.9410\n",
      "Epoch 12/50\n",
      "686/686 [==============================] - 48s 70ms/step - loss: 0.2281 - accuracy: 0.9400 - val_loss: 0.2196 - val_accuracy: 0.9438\n",
      "Epoch 13/50\n",
      "686/686 [==============================] - 48s 71ms/step - loss: 0.2248 - accuracy: 0.9403 - val_loss: 0.2364 - val_accuracy: 0.9374\n",
      "Epoch 14/50\n",
      "686/686 [==============================] - 48s 71ms/step - loss: 0.2155 - accuracy: 0.9433 - val_loss: 0.2287 - val_accuracy: 0.9421\n",
      "Epoch 15/50\n",
      "686/686 [==============================] - 48s 70ms/step - loss: 0.2124 - accuracy: 0.9443 - val_loss: 0.2272 - val_accuracy: 0.9357\n",
      "Epoch 16/50\n",
      "686/686 [==============================] - 49s 71ms/step - loss: 0.2095 - accuracy: 0.9449 - val_loss: 0.2288 - val_accuracy: 0.9426\n",
      "Epoch 17/50\n",
      "686/686 [==============================] - 49s 71ms/step - loss: 0.2026 - accuracy: 0.9475 - val_loss: 0.2353 - val_accuracy: 0.9372\n",
      "Epoch 18/50\n",
      "686/686 [==============================] - 49s 71ms/step - loss: 0.1986 - accuracy: 0.9486 - val_loss: 0.2483 - val_accuracy: 0.9415\n",
      "Epoch 19/50\n",
      "686/686 [==============================] - 48s 71ms/step - loss: 0.1938 - accuracy: 0.9503 - val_loss: 0.2309 - val_accuracy: 0.9396\n",
      "Epoch 20/50\n",
      "686/686 [==============================] - 49s 71ms/step - loss: 0.1940 - accuracy: 0.9492 - val_loss: 0.2372 - val_accuracy: 0.9414\n",
      "Epoch 21/50\n",
      "686/686 [==============================] - 48s 71ms/step - loss: 0.1850 - accuracy: 0.9510 - val_loss: 0.2241 - val_accuracy: 0.9435\n",
      "Epoch 22/50\n",
      "686/686 [==============================] - 48s 71ms/step - loss: 0.1813 - accuracy: 0.9526 - val_loss: 0.2270 - val_accuracy: 0.9443\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(amsgrad = True)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "vgg_model = createVGG16Model(X_train,12)\n",
    "\n",
    "vgg_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "\n",
    "history = vgg_model.fit(datagen.flow(X_train, y_train, batch_size=128),\n",
    "                              epochs=50, validation_data=(X_val, y_val),\n",
    "                               callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "13565834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 4s 20ms/step - loss: 0.2462 - accuracy: 0.9403\n",
      "\n",
      "Loss = 0.2461944967508316\n",
      "Test Accuracy = 0.9403426647186279\n"
     ]
    }
   ],
   "source": [
    "\n",
    "preds_st = vgg_model.evaluate(x= test_x, y=test_labels,  batch_size=128)\n",
    "print()\n",
    "print (\"Loss = \" + str(preds_st[0]))\n",
    "print (\"Test Accuracy = \" + str(preds_st[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d918ff15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "686/686 [==============================] - 48s 70ms/step - loss: 1.2832 - accuracy: 0.5735 - val_loss: 0.5664 - val_accuracy: 0.8351\n",
      "Epoch 2/50\n",
      "686/686 [==============================] - 48s 71ms/step - loss: 0.4955 - accuracy: 0.8662 - val_loss: 0.3493 - val_accuracy: 0.9034\n",
      "Epoch 3/50\n",
      "686/686 [==============================] - 49s 71ms/step - loss: 0.3962 - accuracy: 0.8937 - val_loss: 0.2869 - val_accuracy: 0.9188\n",
      "Epoch 4/50\n",
      "686/686 [==============================] - 49s 71ms/step - loss: 0.3518 - accuracy: 0.9071 - val_loss: 0.2912 - val_accuracy: 0.9194\n",
      "Epoch 5/50\n",
      "686/686 [==============================] - 49s 72ms/step - loss: 0.3283 - accuracy: 0.9142 - val_loss: 0.2779 - val_accuracy: 0.9269\n",
      "Epoch 6/50\n",
      "686/686 [==============================] - 50s 73ms/step - loss: 0.2946 - accuracy: 0.9224 - val_loss: 0.2477 - val_accuracy: 0.9327\n",
      "Epoch 7/50\n",
      "686/686 [==============================] - 50s 73ms/step - loss: 0.2798 - accuracy: 0.9271 - val_loss: 0.2450 - val_accuracy: 0.9330\n",
      "Epoch 8/50\n",
      "686/686 [==============================] - 51s 74ms/step - loss: 0.2667 - accuracy: 0.9296 - val_loss: 0.2429 - val_accuracy: 0.9340\n",
      "Epoch 9/50\n",
      "686/686 [==============================] - 51s 74ms/step - loss: 0.2544 - accuracy: 0.9339 - val_loss: 0.2256 - val_accuracy: 0.9414\n",
      "Epoch 10/50\n",
      "686/686 [==============================] - 51s 75ms/step - loss: 0.2375 - accuracy: 0.9380 - val_loss: 0.2208 - val_accuracy: 0.9412\n",
      "Epoch 11/50\n",
      "686/686 [==============================] - 51s 75ms/step - loss: 0.2359 - accuracy: 0.9382 - val_loss: 0.2415 - val_accuracy: 0.9359\n",
      "Epoch 12/50\n",
      "686/686 [==============================] - 51s 75ms/step - loss: 0.2298 - accuracy: 0.9398 - val_loss: 0.2193 - val_accuracy: 0.9431\n",
      "Epoch 13/50\n",
      "686/686 [==============================] - 51s 74ms/step - loss: 0.2241 - accuracy: 0.9405 - val_loss: 0.2273 - val_accuracy: 0.9412\n",
      "Epoch 14/50\n",
      "686/686 [==============================] - 51s 75ms/step - loss: 0.2136 - accuracy: 0.9441 - val_loss: 0.2234 - val_accuracy: 0.9416\n",
      "Epoch 15/50\n",
      "686/686 [==============================] - 51s 75ms/step - loss: 0.2015 - accuracy: 0.9466 - val_loss: 0.2230 - val_accuracy: 0.9408\n",
      "Epoch 16/50\n",
      "686/686 [==============================] - 52s 75ms/step - loss: 0.2011 - accuracy: 0.9476 - val_loss: 0.2173 - val_accuracy: 0.9430\n",
      "Epoch 17/50\n",
      "686/686 [==============================] - 52s 76ms/step - loss: 0.1909 - accuracy: 0.9502 - val_loss: 0.2234 - val_accuracy: 0.9439\n",
      "Epoch 18/50\n",
      "686/686 [==============================] - 52s 76ms/step - loss: 0.1882 - accuracy: 0.9514 - val_loss: 0.2272 - val_accuracy: 0.9442\n",
      "Epoch 19/50\n",
      "686/686 [==============================] - 52s 75ms/step - loss: 0.1859 - accuracy: 0.9515 - val_loss: 0.2174 - val_accuracy: 0.9443\n",
      "Epoch 20/50\n",
      "686/686 [==============================] - 52s 75ms/step - loss: 0.1809 - accuracy: 0.9532 - val_loss: 0.2342 - val_accuracy: 0.9458\n",
      "Epoch 21/50\n",
      "686/686 [==============================] - 52s 76ms/step - loss: 0.1811 - accuracy: 0.9534 - val_loss: 0.2185 - val_accuracy: 0.9462\n",
      "Epoch 22/50\n",
      "686/686 [==============================] - 52s 75ms/step - loss: 0.1324 - accuracy: 0.9660 - val_loss: 0.1979 - val_accuracy: 0.9516\n",
      "Epoch 23/50\n",
      "686/686 [==============================] - 52s 76ms/step - loss: 0.1171 - accuracy: 0.9700 - val_loss: 0.2052 - val_accuracy: 0.9513\n",
      "Epoch 24/50\n",
      "686/686 [==============================] - 52s 76ms/step - loss: 0.1091 - accuracy: 0.9714 - val_loss: 0.2031 - val_accuracy: 0.9519\n",
      "Epoch 25/50\n",
      "686/686 [==============================] - 52s 76ms/step - loss: 0.1066 - accuracy: 0.9727 - val_loss: 0.2036 - val_accuracy: 0.9521\n",
      "Epoch 26/50\n",
      "686/686 [==============================] - 52s 76ms/step - loss: 0.1010 - accuracy: 0.9742 - val_loss: 0.2140 - val_accuracy: 0.9518\n",
      "Epoch 27/50\n",
      "686/686 [==============================] - 52s 76ms/step - loss: 0.0965 - accuracy: 0.9754 - val_loss: 0.2162 - val_accuracy: 0.9525\n",
      "Epoch 28/50\n",
      "686/686 [==============================] - 52s 76ms/step - loss: 0.0888 - accuracy: 0.9772 - val_loss: 0.2201 - val_accuracy: 0.9512\n",
      "Epoch 29/50\n",
      "686/686 [==============================] - 52s 76ms/step - loss: 0.0854 - accuracy: 0.9782 - val_loss: 0.2260 - val_accuracy: 0.9519\n",
      "Epoch 30/50\n",
      "686/686 [==============================] - 52s 76ms/step - loss: 0.0841 - accuracy: 0.9785 - val_loss: 0.2250 - val_accuracy: 0.9524\n",
      "Epoch 31/50\n",
      "686/686 [==============================] - 52s 76ms/step - loss: 0.0809 - accuracy: 0.9797 - val_loss: 0.2273 - val_accuracy: 0.9517\n",
      "Epoch 32/50\n",
      "686/686 [==============================] - 52s 76ms/step - loss: 0.0787 - accuracy: 0.9800 - val_loss: 0.2282 - val_accuracy: 0.9520\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                              patience=5, min_lr=0.0001)\n",
    "optimizer = tf.keras.optimizers.Adam(amsgrad = True)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "vgg_model_reduce_lr = createVGG16Model(X_train,12)\n",
    "\n",
    "vgg_model_reduce_lr.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "\n",
    "history = vgg_model_reduce_lr.fit(datagen.flow(X_train, y_train, batch_size=128),\n",
    "                              epochs=50, validation_data=(X_val, y_val),\n",
    "                               callbacks=[early_stopping,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b2dd1997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.22064294469356535\n",
      "Test Accuracy = 9481202582465012\n"
     ]
    }
   ],
   "source": [
    "preds_reduce_lr = vgg_model.evaluate(x= test_x, y=test_labels,  batch_size=128)\n",
    "print (\"Loss = \" + str(preds_reduce_lr[0]))\n",
    "print (\"Test Accuracy = \" + str(preds_reduce_lr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4c97ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.optimizers import CyclicalLearningRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "319730cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_within_each_step = 3\n",
    "iterations_in_epoch = len(X_train) / 128\n",
    "step_size = iterations_in_epoch * epochs_within_each_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5d5e74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclical_learning_rate = CyclicalLearningRate(\n",
    " initial_learning_rate=(1e-4),\n",
    " maximal_learning_rate=(1e-3),\n",
    " step_size=step_size,\n",
    " scale_fn=lambda x: 1 / (2.0 ** (x - 1)),\n",
    " scale_mode='cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6ff6b6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "686/686 [==============================] - 46s 67ms/step - loss: 0.6261 - accuracy: 0.8145 - val_loss: 0.3368 - val_accuracy: 0.9096\n",
      "Epoch 2/50\n",
      "686/686 [==============================] - 46s 67ms/step - loss: 0.3935 - accuracy: 0.8971 - val_loss: 0.3222 - val_accuracy: 0.9208\n",
      "Epoch 3/50\n",
      "686/686 [==============================] - 46s 67ms/step - loss: 0.3827 - accuracy: 0.9020 - val_loss: 0.3616 - val_accuracy: 0.9020\n",
      "Epoch 4/50\n",
      "686/686 [==============================] - 47s 68ms/step - loss: 0.3140 - accuracy: 0.9198 - val_loss: 0.2284 - val_accuracy: 0.9421\n",
      "Epoch 5/50\n",
      "686/686 [==============================] - 47s 69ms/step - loss: 0.2269 - accuracy: 0.9418 - val_loss: 0.1805 - val_accuracy: 0.9516\n",
      "Epoch 6/50\n",
      "686/686 [==============================] - 48s 69ms/step - loss: 0.1666 - accuracy: 0.9567 - val_loss: 0.1613 - val_accuracy: 0.9571oss: 0.1666 - \n",
      "Epoch 7/50\n",
      "686/686 [==============================] - 48s 70ms/step - loss: 0.1385 - accuracy: 0.9649 - val_loss: 0.1750 - val_accuracy: 0.9569\n",
      "Epoch 8/50\n",
      "686/686 [==============================] - 48s 70ms/step - loss: 0.1450 - accuracy: 0.9630 - val_loss: 0.1730 - val_accuracy: 0.9549\n",
      "Epoch 9/50\n",
      "686/686 [==============================] - 48s 70ms/step - loss: 0.1559 - accuracy: 0.9592 - val_loss: 0.1972 - val_accuracy: 0.9498\n",
      "Epoch 10/50\n",
      "686/686 [==============================] - 48s 70ms/step - loss: 0.1535 - accuracy: 0.9611 - val_loss: 0.1788 - val_accuracy: 0.9540\n",
      "Epoch 11/50\n",
      "686/686 [==============================] - 48s 70ms/step - loss: 0.1171 - accuracy: 0.9705 - val_loss: 0.1730 - val_accuracy: 0.9561\n",
      "Epoch 12/50\n",
      "686/686 [==============================] - 49s 71ms/step - loss: 0.0867 - accuracy: 0.9788 - val_loss: 0.1733 - val_accuracy: 0.9599\n",
      "Epoch 13/50\n",
      "686/686 [==============================] - 49s 71ms/step - loss: 0.0716 - accuracy: 0.9833 - val_loss: 0.1811 - val_accuracy: 0.9603\n",
      "Epoch 14/50\n",
      "686/686 [==============================] - 49s 71ms/step - loss: 0.0720 - accuracy: 0.9826 - val_loss: 0.1875 - val_accuracy: 0.9582\n",
      "Epoch 15/50\n",
      "686/686 [==============================] - 49s 71ms/step - loss: 0.0806 - accuracy: 0.9801 - val_loss: 0.1983 - val_accuracy: 0.9534\n",
      "Epoch 16/50\n",
      "686/686 [==============================] - 49s 71ms/step - loss: 0.0755 - accuracy: 0.9819 - val_loss: 0.2029 - val_accuracy: 0.9555\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate = cyclical_learning_rate,amsgrad = True)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "vgg_cyclic = createVGG16Model(X_train,12)\n",
    "\n",
    "vgg_cyclic.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "\n",
    "history_cyclic = vgg_cyclic.fit(datagen.flow(X_train, y_train, batch_size=128),\n",
    "                              epochs=50, validation_data=(X_val, y_val),\n",
    "                               callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3f7da063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.20064294469356536\n",
      "Test Accuracy = 0.9561955786705016\n"
     ]
    }
   ],
   "source": [
    "preds_cyclic = vgg_cyclic.evaluate(x= test_x, y=test_labels,  batch_size=128)\n",
    "print()\n",
    "print (\"Loss = \" + str(preds_cyclic[0]))\n",
    "print (\"Test Accuracy = \" + str(preds_cyclic[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c563b7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'LearningRateType': [], 'TestSetAccuracy': []}\n",
    "\n",
    "results['LearningRateType'].append('Standard')\n",
    "results['TestSetAccuracy'].append(preds_st[0])\n",
    "\n",
    "results['LearningRateType'].append('ReduceLROnPlateau')\n",
    "results['TestSetAccuracy'].append(preds_reduce_lr[1])\n",
    "\n",
    "results['LearningRateType'].append('Cyclic')\n",
    "results['TestSetAccuracy'].append(0.956)\n",
    "\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ed6234d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "g = sns.barplot(x=\"LearningRateType\", y=\"TestSetAccuracy\", data=results_df)\n",
    "\n",
    "ax=g\n",
    "#annotate axis = seaborn axis\n",
    "for p in ax.patches:\n",
    "             ax.annotate(\"%.3f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='center', fontsize=11, color='gray', xytext=(0, 20),\n",
    "                 textcoords='offset points')\n",
    "_ = g.set_ylim(0,1) #To make space for the annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclical_learning_rate_first = CyclicalLearningRate(\n",
    " initial_learning_rate=(1e-4),\n",
    " maximal_learning_rate=(1e-3),\n",
    " step_size=step_size,\n",
    " scale_fn=lambda x: 1 / (2.0 ** (x - 1)),\n",
    " scale_mode='cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80e98b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1815/1815 [==============================] - 124s 68ms/step - loss: 0.3535 - accuracy: 0.9026 - val_loss: 0.1749 - val_accuracy: 0.9513\n",
      "Epoch 2/60\n",
      "1815/1815 [==============================] - 123s 68ms/step - loss: 0.2314 - accuracy: 0.9418 - val_loss: 0.1684 - val_accuracy: 0.9563\n",
      "Epoch 3/60\n",
      "1815/1815 [==============================] - 125s 69ms/step - loss: 0.2204 - accuracy: 0.9453 - val_loss: 0.1681 - val_accuracy: 0.9572\n",
      "Epoch 4/60\n",
      "1815/1815 [==============================] - 126s 69ms/step - loss: 0.1822 - accuracy: 0.9550 - val_loss: 0.1398 - val_accuracy: 0.9650\n",
      "Epoch 5/60\n",
      "1815/1815 [==============================] - 128s 70ms/step - loss: 0.1281 - accuracy: 0.9679 - val_loss: 0.1051 - val_accuracy: 0.9735\n",
      "Epoch 6/60\n",
      "1815/1815 [==============================] - 129s 71ms/step - loss: 0.0920 - accuracy: 0.9769 - val_loss: 0.0915 - val_accuracy: 0.9757\n",
      "Epoch 7/60\n",
      "1815/1815 [==============================] - 129s 71ms/step - loss: 0.0783 - accuracy: 0.9805 - val_loss: 0.0969 - val_accuracy: 0.9757\n",
      "Epoch 8/60\n",
      "1815/1815 [==============================] - 129s 71ms/step - loss: 0.0793 - accuracy: 0.9798 - val_loss: 0.1048 - val_accuracy: 0.9731\n",
      "Epoch 9/60\n",
      "1815/1815 [==============================] - 129s 71ms/step - loss: 0.0881 - accuracy: 0.9779 - val_loss: 0.1155 - val_accuracy: 0.9698\n",
      "Epoch 10/60\n",
      "1815/1815 [==============================] - 130s 72ms/step - loss: 0.0866 - accuracy: 0.9782 - val_loss: 0.1066 - val_accuracy: 0.9744\n",
      "Epoch 11/60\n",
      "1815/1815 [==============================] - 129s 71ms/step - loss: 0.0675 - accuracy: 0.9836 - val_loss: 0.0975 - val_accuracy: 0.9758\n",
      "Epoch 12/60\n",
      "1815/1815 [==============================] - 131s 72ms/step - loss: 0.0513 - accuracy: 0.9880 - val_loss: 0.0977 - val_accuracy: 0.9767\n",
      "Epoch 13/60\n",
      "1815/1815 [==============================] - 131s 72ms/step - loss: 0.0429 - accuracy: 0.9902 - val_loss: 0.1066 - val_accuracy: 0.9765\n",
      "Epoch 14/60\n",
      "1815/1815 [==============================] - 131s 72ms/step - loss: 0.0439 - accuracy: 0.9898 - val_loss: 0.1098 - val_accuracy: 0.9751\n",
      "Epoch 15/60\n",
      "1815/1815 [==============================] - 131s 72ms/step - loss: 0.0477 - accuracy: 0.9885 - val_loss: 0.1081 - val_accuracy: 0.9760\n",
      "Epoch 16/60\n",
      "1815/1815 [==============================] - 131s 72ms/step - loss: 0.0462 - accuracy: 0.9891 - val_loss: 0.1096 - val_accuracy: 0.9761\n"
     ]
    }
   ],
   "source": [
    "# Iteration 1\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = cyclical_learning_rate_first,amsgrad = True)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "vgg_cyclic_extra = createVGG16Model(X_train,12)\n",
    "\n",
    "vgg_cyclic_extra.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "\n",
    "history_cyclic_first = vgg_cyclic_extra.fit(datagen.flow(X_train, y_train, batch_size=128),\n",
    "                              epochs=60, validation_data=(X_val, y_val),\n",
    "                               callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e462d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 5s 22ms/step - loss: 0.1581 - accuracy: 0.9657\n",
      "\n",
      "Loss = 0.15806366503238678\n",
      "Test Accuracy = 0.9656960368156433\n"
     ]
    }
   ],
   "source": [
    "#newww\n",
    "preds_extra = vgg_cyclic_extra.evaluate(x= test_x, y=test_labels,  batch_size=128)\n",
    "print()\n",
    "print (\"Loss = \" + str(preds_extra[0]))\n",
    "print (\"Test Accuracy = \" + str(preds_extra[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a5023039",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclical_learning_rate_next = CyclicalLearningRate(\n",
    " initial_learning_rate=(2e-5),\n",
    " maximal_learning_rate=(1e-4),\n",
    " step_size=step_size,\n",
    " scale_fn=lambda x: 1 / (2.0 ** (x - 1)),\n",
    " scale_mode='cycle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "216a0fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copying the weights to start the new iteration with reduced cyclical learning rate\n",
    "vgg_next_iter = keras.models.clone_model(vgg_cyclic_extra)\n",
    "\n",
    "vgg_next_iter.set_weights(vgg_cyclic_extra.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8b66b292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "   2/1815 [..............................] - ETA: 1:02 - loss: 0.0471 - accuracy: 0.9844WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0263s vs `on_train_batch_end` time: 0.0438s). Check your callbacks.\n",
      "1815/1815 [==============================] - 123s 68ms/step - loss: 0.0317 - accuracy: 0.9928 - val_loss: 0.1184 - val_accuracy: 0.9757\n",
      "Epoch 2/60\n",
      "1815/1815 [==============================] - 127s 70ms/step - loss: 0.0304 - accuracy: 0.9933 - val_loss: 0.1209 - val_accuracy: 0.9753\n",
      "Epoch 3/60\n",
      "1815/1815 [==============================] - 129s 71ms/step - loss: 0.0312 - accuracy: 0.9929 - val_loss: 0.1233 - val_accuracy: 0.9751\n",
      "Epoch 4/60\n",
      "1815/1815 [==============================] - 130s 72ms/step - loss: 0.0297 - accuracy: 0.9931 - val_loss: 0.1227 - val_accuracy: 0.9751\n",
      "Epoch 5/60\n",
      "1815/1815 [==============================] - 130s 72ms/step - loss: 0.0218 - accuracy: 0.9949 - val_loss: 0.1331 - val_accuracy: 0.9757\n",
      "Epoch 6/60\n",
      "1815/1815 [==============================] - 130s 72ms/step - loss: 0.0176 - accuracy: 0.9962 - val_loss: 0.1390 - val_accuracy: 0.9762\n",
      "Epoch 7/60\n",
      "1815/1815 [==============================] - 131s 72ms/step - loss: 0.0151 - accuracy: 0.9967 - val_loss: 0.1427 - val_accuracy: 0.9762\n",
      "Epoch 8/60\n",
      "1815/1815 [==============================] - 131s 72ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.1449 - val_accuracy: 0.9759\n",
      "Epoch 9/60\n",
      "1815/1815 [==============================] - 131s 72ms/step - loss: 0.0145 - accuracy: 0.9966 - val_loss: 0.1546 - val_accuracy: 0.9750\n",
      "Epoch 10/60\n",
      "1815/1815 [==============================] - 132s 72ms/step - loss: 0.0141 - accuracy: 0.9968 - val_loss: 0.1494 - val_accuracy: 0.9762\n",
      "Epoch 11/60\n",
      "1815/1815 [==============================] - 131s 72ms/step - loss: 0.0125 - accuracy: 0.9971 - val_loss: 0.1522 - val_accuracy: 0.9763\n"
     ]
    }
   ],
   "source": [
    "#Iteration 2\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = cyclical_learning_rate_next,amsgrad = True)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "\n",
    "vgg_next_iter.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "\n",
    "history_cyclic_next = vgg_next_iter.fit(datagen.flow(X_train, y_train, batch_size=128),\n",
    "                              epochs=60, validation_data=(X_val, y_val),\n",
    "                               callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "499441be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204/204 [==============================] - 4s 21ms/step - loss: 0.2098 - accuracy: 0.9667\n",
      "\n",
      "Loss = 0.20981155335903168\n",
      "Test Accuracy = 0.9666948318481445\n"
     ]
    }
   ],
   "source": [
    "preds_next_iter = vgg_next_iter.evaluate(x= test_x, y=test_labels,  batch_size=128)\n",
    "print()\n",
    "print (\"Loss = \" + str(preds_next_iter[0]))\n",
    "print (\"Test Accuracy = \" + str(preds_next_iter[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f203b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {'Accuracy' : [], 'Type' : ['Train','Test','Train','Test'], 'CyclicIteration': [1,1,2,2]}\n",
    "\n",
    "result['Accuracy'].append(history_cyclic_history_cyclic_first.history['accuracy'][-1])\n",
    "result['Accuracy'].append(preds_extra[1])\n",
    "\n",
    "result['Accuracy'].append(history_cyclic_next.history['accuracy'][-1])\n",
    "result['Accuracy'].append(preds_next_iter[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "98167fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Type</th>\n",
       "      <th>CyclicIteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.989133</td>\n",
       "      <td>Train</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.965696</td>\n",
       "      <td>Test</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.997107</td>\n",
       "      <td>Train</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.966695</td>\n",
       "      <td>Test</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy   Type  CyclicIteration\n",
       "0  0.989133  Train                1\n",
       "1  0.965696   Test                1\n",
       "2  0.997107  Train                2\n",
       "3  0.966695   Test                2"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(result)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "35a1d82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "g = sns.barplot(x=\"CyclicIteration\", y=\"Accuracy\", hue = 'Type', data=results)\n",
    "\n",
    "ax=g\n",
    "\n",
    "for p in ax.patches:\n",
    "             ax.annotate(\"%.3f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                 ha='center', va='center', fontsize=11, color='gray', xytext=(0, 20),\n",
    "                 textcoords='offset points')\n",
    "_ = g.set_ylim(0,1) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
